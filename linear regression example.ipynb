{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random(1000)\n",
    "labels = data * 3 + 1\n",
    "\n",
    "randomize = np.arange(len(data))\n",
    "np.random.shuffle(randomize)\n",
    "split = int(.8 * len(data))\n",
    "\n",
    "train_data = data[randomize][:split]\n",
    "train_labels = labels[randomize][:split]\n",
    "val_data = data[randomize][split:]\n",
    "val_labels = labels[randomize][split:]\n",
    "\n",
    "test_data = np.random.random(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s - loss: 2.9707 - val_loss: 1.5981\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s - loss: 0.9621 - val_loss: 0.5787\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s - loss: 0.3824 - val_loss: 0.2749\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s - loss: 0.2101 - val_loss: 0.1795\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s - loss: 0.1551 - val_loss: 0.1446\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s - loss: 0.1330 - val_loss: 0.1276\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s - loss: 0.1209 - val_loss: 0.1170\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s - loss: 0.1122 - val_loss: 0.1086\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s - loss: 0.1046 - val_loss: 0.1012\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s - loss: 0.0977 - val_loss: 0.0945\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s - loss: 0.0914 - val_loss: 0.0884\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s - loss: 0.0855 - val_loss: 0.0826\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s - loss: 0.0800 - val_loss: 0.0772\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s - loss: 0.0748 - val_loss: 0.0723\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s - loss: 0.0699 - val_loss: 0.0676\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s - loss: 0.0654 - val_loss: 0.0632\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s - loss: 0.0612 - val_loss: 0.0591\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s - loss: 0.0572 - val_loss: 0.0553\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s - loss: 0.0535 - val_loss: 0.0517\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s - loss: 0.0501 - val_loss: 0.0484\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s - loss: 0.0468 - val_loss: 0.0452\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s - loss: 0.0438 - val_loss: 0.0423\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s - loss: 0.0410 - val_loss: 0.0396\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s - loss: 0.0383 - val_loss: 0.0370\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s - loss: 0.0358 - val_loss: 0.0346\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s - loss: 0.0335 - val_loss: 0.0324\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s - loss: 0.0314 - val_loss: 0.0303\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s - loss: 0.0293 - val_loss: 0.0283\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s - loss: 0.0274 - val_loss: 0.0265\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s - loss: 0.0256 - val_loss: 0.0248\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s - loss: 0.0240 - val_loss: 0.0232\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s - loss: 0.0224 - val_loss: 0.0217\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s - loss: 0.0210 - val_loss: 0.0203\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s - loss: 0.0196 - val_loss: 0.0190\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s - loss: 0.0172 - val_loss: 0.0166\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s - loss: 0.0150 - val_loss: 0.0145\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.010 - 0s - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s - loss: 0.0010 - val_loss: 9.9922e-04\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s - loss: 9.6735e-04 - val_loss: 9.3436e-04\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s - loss: 9.0482e-04 - val_loss: 8.7387e-04\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s - loss: 8.4612e-04 - val_loss: 8.1758e-04\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s - loss: 7.9167e-04 - val_loss: 7.6460e-04\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s - loss: 7.4051e-04 - val_loss: 7.1539e-04\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s - loss: 6.9227e-04 - val_loss: 6.6935e-04\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s - loss: 6.4759e-04 - val_loss: 6.2608e-04\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s - loss: 6.0566e-04 - val_loss: 5.8514e-04\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s - loss: 5.6673e-04 - val_loss: 5.4697e-04\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s - loss: 5.2994e-04 - val_loss: 5.1170e-04\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s - loss: 4.9557e-04 - val_loss: 4.7847e-04\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s - loss: 4.6357e-04 - val_loss: 4.4757e-04\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s - loss: 4.3372e-04 - val_loss: 4.1877e-04\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s - loss: 4.0555e-04 - val_loss: 3.9152e-04\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s - loss: 3.7935e-04 - val_loss: 3.6627e-04\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s - loss: 3.5469e-04 - val_loss: 3.4251e-04\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s - loss: 3.3170e-04 - val_loss: 3.2037e-04\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s - loss: 3.1029e-04 - val_loss: 2.9980e-04\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s - loss: 2.9027e-04 - val_loss: 2.8042e-04\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s - loss: 2.7153e-04 - val_loss: 2.6222e-04\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s - loss: 2.5390e-04 - val_loss: 2.4530e-04\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s - loss: 2.3747e-04 - val_loss: 2.2936e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1))\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error')\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "hist = model.fit(train_data, train_labels, \n",
    "                 validation_data=(val_data, val_labels),  epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1204c61d0>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120027590>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1200274d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data, labels)\n",
    "plt.plot(test_data, prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
